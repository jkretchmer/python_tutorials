{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem Set 2 - Arctic ice maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total points:** 30\n",
    "\n",
    "**Due:** Thursday November 5th, 7pm CET\n",
    "\n",
    "**Format:** IPython Notebook or python program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this problem set is to become familiar with working with image data, plotting it, and combining it in various ways for analysis.\n",
    "\n",
    "The data used in this problem set were collected by the AMSR-E and AMSR2 instruments on the [Aqua](http://en.wikipedia.org/wiki/Aqua_%28satellite%29) satellite and [GCOM-W1 satellites](https://en.wikipedia.org/wiki/Global_Change_Observation_Mission). The data consists of maps of the concentration of ice in the Arctic collected between 2002 and 2019. The concentration is defined  the percentage of a given area covered with sea ice. The data were downloaded and extracted from [here](http://seaice.uni-bremen.de/data/) and converted into a format that can be more easily used.\n",
    "\n",
    "The data you should use are situated in the data/ice_data_2019/ directory on the jupyter server.\n",
    "\n",
    "If you are using your own laptop, you can dowload the data [here](http://wwwstaff.ari.uni-heidelberg.de/rschmidt/pycourse/ice_data.tgz) (or [this link](http://wwwstaff.ari.uni-heidelberg.de/rschmidt/pycourse/ice_data.zip) if you need a zip archive). The archive size is 63MB.\n",
    "\n",
    "The data is in 'Numpy' format, which means that you can read it as a Numpy array using:\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> data = np.load('data/ice_data_2019/20080415.npy')\n",
    "\n",
    "which will give you a 2-d array. Just for information, this was created with:\n",
    "\n",
    "    >>> np.save('data/ice_data_2019/20080415.npy', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - examining a single map (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start off by reading in one of the maps as shown above, and plot it with Matplotlib**. Note that to get the correct orientation, you will need to call the ``imshow`` command with the ``origin='lower'`` option, which ensures that the (0,0) pixels is on the bottom left, not the top left. You can try and use different colormaps if you like (set by the ``cmap`` option) - see [here](http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps) for information on the available colormaps. You can specify a colormap to use with e.g. ``cmap=plt.cm.jet`` (i.e. ``cmap=plt.cm.`` followed by the name of the colormap). Note that you can make figures larger by specifying before the plot command for example\n",
    "\n",
    "    >>> plt.figure(figsize=(8,8))\n",
    "\n",
    "where the size is given in inches. Try and find a way to plot a colorbar on the side, to show what color corresponds to what value. Examples can be found in the [Matplotlib Gallery](http://matplotlib.org/gallery.html). You may also want to try to remove the tick labels (``100``, ``200``, etc.) since they are not useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - reading in multiple maps (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1**  We want to make a plot of the ice concentration over time. Reading in a single map is easy, but since we have 396 maps, we do not want to read them all in individually by hand. **Write a loop over all the available files, and inside the loop, read in the data to a variable (e.g. ``data``), and also extract the year, month, and day as integer values (e.g. ``year``, ``month``, and ``day``)**. Then, also inside the loop, **compute a variable ``time``** which is essentially the fractional time in years (so 1st July 2012 is 2012.5). You can assume for simplicity that each month has 30 days - this will not affect the results later. Finally, also **compute for each file the total number of pixels that have a value above 50%**. After the loop, **make a plot of the number of pixels with a concentration above 50% against time**.\n",
    "\n",
    "**Describe what you see in the plot**.\n",
    "\n",
    "\n",
    "In some version of jupyter, the ticks are in a strange format. In this case you can change this with the following code:\n",
    "\n",
    "    >>> from matplotlib.ticker import ScalarFormatter\n",
    "    >>> plt.gca().xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    \n",
    "    \n",
    "In all other cases, you can ignore these lines.\n",
    "\n",
    "\n",
    "**2.2**  To deal with a little more than just the number of pixels, so we will compute the area where the ice concentration is above a given threshold. However, we first need to know the area of the pixels in the image, and since we are looking at a projection of a spherical surface, each pixel will be a different area. The areas (in km^2) are contained inside the file named ``ice_data_2019_area.npy``. This file was downladed [here](https://seaice.uni-bremen.de/data/grid_coordinates/GridCellArea/) (PolStereo_GridCellArea_n12.5km_Arctic.nc) and then converted.\n",
    "\n",
    "**Read in the areas and make a plot (with colorbar) to see how the pixel area is changing over the image.**\n",
    "\n",
    "Now, loop over the files again as before, but this time, for each file, **compute the total area where the concentration of ice is 15% or above. Make a new plot showing the area of >15% ice concentration against time.**\n",
    "\n",
    "**Describe what you see - how does the minimum change over time?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - visualizing changes over time (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the date at which the area of the region where the ice concentration is above 15% is the smallest**. What is the value of the minimum area?\n",
    "\n",
    "Next, **read in the map for this minimum, and the map for the same day and month but from 2006**. **Make a side-by-side plot showing both data sets**.\n",
    "\n",
    "**Compute the difference between the two maps** so that a loss in ice over time will correspond to a negative value, and a gain in ice will correspond to a positive value. **Make a plot** of the difference, and use the ``RdBu`` colormap to highlight the changes (include a colorbar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - yearly averages (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute average ice concentration maps for 2006 and 2012, and plot them side by side.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have here only cover 18 years, so we cannot easily extract information about long term trends. However, it is worth noting that the minimum ice coverage you find here is a record minimum - never before (in recorded history) had the size of the ice shelf been so small. This is part of a long term trend due to global warming. Most scientists believe that by ~2050, the Arctic will be completely ice-free for at least part of the summer."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
